{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-25T14:50:30.249142Z",
     "start_time": "2025-08-25T14:50:28.702957Z"
    }
   },
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from diffusion_1d.core.ddpm_1d import DDPM\n",
    "from diffusion_1d.core.noise_scheduler_1d import DDPMScheduler\n",
    "from diffusion_1d.models.unet_1d import SimpleUNet\n",
    "from diffusion_1d.data.synthetic import create_toy_dataset\n",
    "from diffusion_1d.evaluation.visualization import *\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.3.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/jantinebroek/miniconda3/envs/diff_gnn/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/jantinebroek/miniconda3/envs/diff_gnn/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/jantinebroek/miniconda3/envs/diff_gnn/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/jantinebroek/miniconda3/envs/diff_gnn/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Users/jantinebroek/miniconda3/envs/diff_gnn/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Users/jantinebroek/miniconda3/envs/diff_gnn/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Users/jantinebroek/miniconda3/envs/diff_gnn/lib/python3.11/asyncio/events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/jantinebroek/miniconda3/envs/diff_gnn/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 519, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/jantinebroek/miniconda3/envs/diff_gnn/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 508, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/jantinebroek/miniconda3/envs/diff_gnn/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 400, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/jantinebroek/miniconda3/envs/diff_gnn/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 368, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/jantinebroek/miniconda3/envs/diff_gnn/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/jantinebroek/miniconda3/envs/diff_gnn/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 455, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/jantinebroek/miniconda3/envs/diff_gnn/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 577, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/jantinebroek/miniconda3/envs/diff_gnn/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/jantinebroek/miniconda3/envs/diff_gnn/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/jantinebroek/miniconda3/envs/diff_gnn/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/jantinebroek/miniconda3/envs/diff_gnn/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/jantinebroek/miniconda3/envs/diff_gnn/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/jantinebroek/miniconda3/envs/diff_gnn/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/bs/gvm42h356mz5vjf9v118br000000gn/T/ipykernel_56252/63328468.py\", line 4, in <module>\n",
      "    from torch.utils.data import DataLoader, TensorDataset\n",
      "  File \"/Users/jantinebroek/miniconda3/envs/diff_gnn/lib/python3.11/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/jantinebroek/miniconda3/envs/diff_gnn/lib/python3.11/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/jantinebroek/miniconda3/envs/diff_gnn/lib/python3.11/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/jantinebroek/miniconda3/envs/diff_gnn/lib/python3.11/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/jantinebroek/miniconda3/envs/diff_gnn/lib/python3.11/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/jantinebroek/miniconda3/envs/diff_gnn/lib/python3.11/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T14:50:30.258871Z",
     "start_time": "2025-08-25T14:50:30.255698Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ],
   "id": "caef2400e4f5b56b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T14:50:30.485465Z",
     "start_time": "2025-08-25T14:50:30.474796Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create small dataset for quick testing\n",
    "dataset = create_toy_dataset(n_samples=100, seq_len=32)\n",
    "dataloader = DataLoader(TensorDataset(dataset), batch_size=8, shuffle=True)\n",
    "\n",
    "# Get samples and unpack immediately\n",
    "samples_tuple = next(iter(dataloader))\n",
    "samples = samples_tuple[0]  # Unpack the tensor from TensorDataset wrapper\n"
   ],
   "id": "94efa6ba53330cac",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T14:50:30.504583Z",
     "start_time": "2025-08-25T14:50:30.497657Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize components\n",
    "scheduler = DDPMScheduler(num_timesteps=100)  # Fewer steps for quick demo\n",
    "model = SimpleUNet(dim=32, channels=1).to(device)\n",
    "ddpm = DDPM(model, scheduler, device)"
   ],
   "id": "4073a0408d98de6d",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T14:50:30.752757Z",
     "start_time": "2025-08-25T14:50:30.516646Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Visualize original data\n",
    "plt.figure(figsize=(12, 3))\n",
    "for i in range(4):\n",
    "    plt.subplot(1, 4, i+1)\n",
    "    plt.plot(samples[i, 0].numpy())\n",
    "    plt.title(f'Original {i+1}')\n",
    "plt.suptitle('Original Training Data')\n",
    "plt.show()"
   ],
   "id": "1d97c52a673e4bf8",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Numpy is not available",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mRuntimeError\u001B[39m                              Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[5]\u001B[39m\u001B[32m, line 5\u001B[39m\n\u001B[32m      3\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[32m4\u001B[39m):\n\u001B[32m      4\u001B[39m     plt.subplot(\u001B[32m1\u001B[39m, \u001B[32m4\u001B[39m, i+\u001B[32m1\u001B[39m)\n\u001B[32m----> \u001B[39m\u001B[32m5\u001B[39m     plt.plot(\u001B[43msamples\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m.\u001B[49m\u001B[43mnumpy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[32m      6\u001B[39m     plt.title(\u001B[33mf\u001B[39m\u001B[33m'\u001B[39m\u001B[33mOriginal \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi+\u001B[32m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m'\u001B[39m)\n\u001B[32m      7\u001B[39m plt.suptitle(\u001B[33m'\u001B[39m\u001B[33mOriginal Training Data\u001B[39m\u001B[33m'\u001B[39m)\n",
      "\u001B[31mRuntimeError\u001B[39m: Numpy is not available"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x300 with 1 Axes>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQgAAAEYCAYAAACgIGhkAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjUsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvWftoOwAAAAlwSFlzAAAPYQAAD2EBqD+naQAAGZlJREFUeJzt3H1QVOfZBvBr1x1YIhoFlGmaxlStSLaAC5ualE3t1GDVSAQ1Vk38SESJNdpJmpqAk4ChVmucZGpsJ36UloxOJzJqbI3Bj2g6HRs1xbAEIymIUTt+sHwpssvihvv9g7J1xSfx4J4V9r1+M/vHefY5u/c9h3PtOWf3YBARARHRTRjvdAFE1HMxIIhIiQFBREoMCCJSYkAQkRIDgoiUGBBEpMSAICIlBgQRKXU7INra2jBp0iQcPXpUOefzzz/HE088gaSkJEydOhUVFRXdfTsiugO6FRAejwcvvPACqqqqlHNcLhcWLlwIm82GHTt2wGq1Ijs7Gy6Xq9vFElFwaQ6I6upqTJ8+HWfPnv3aeXv27EF4eDiWLVuGYcOGYfny5ejbty9KSkq6XSwRBZfmgDh27BhGjx6Nd99992vnORwOpKSkwGAwAAAMBgOSk5NRVlbWrUKJKPhMWleYNWvWLc1zOp0YPny431h0dPTXnpYQUc+i27cYbrcbYWFhfmNhYWFoa2vT6y2JKMA0H0HcqvDw8C5h0NbWBrPZrOl1Ghqa0dv/Y4XBAERF9ev1vYRKH0Do9NLZh150C4jY2FjU1dX5jdXV1WHw4MGaXkcEaG8PZGXB99/LMGhvR6//YwR6fx9A6PRi1PmXTLq9fFJSEj799FN0/sMqEcHx48eRlJSk11sSUYAFNCCcTidaW1sBAOPHj8eVK1ewcuVKVFdXY+XKlXC73ZgwYUIg35KIdBTQgLDb7dizZw8AIDIyEhs2bEBpaSmmTJkCh8OBjRs34q677grkWxKRjgw9/Z/W1tc3h8Q1iJiYfqir6/0XxEKhDyB0ejEageho/S5S8mYtIlJiQBCREgOCiJQYEESkxIAgIiUGBBEpMSCISIkBQURKDAgiUmJAEJESA4KIlBgQRKTEgCAiJQYEESkxIIhIiQFBREoMCCJSYkAQkRIDgoiUGBBEpMSAICIlBgQRKTEgiEiJAUFESgwIIlJiQBCREgOCiJQYEESkxIAgIiUGBBEpMSCISIkBQURKDAgiUmJAEJGS5oDweDzIzc2FzWaD3W5HYWGhcu7+/fsxYcIEWK1WzJw5EydOnLitYokouDQHxJo1a1BRUYGioiLk5eVh/fr1KCkp6TKvqqoKv/zlL5GdnY1du3YhPj4e2dnZcLvdASmciPSnKSBcLheKi4uxfPlyWCwWpKWlISsrC1u3bu0y9/Dhwxg+fDgyMjJw33334YUXXoDT6UR1dXXAiicifWkKiMrKSni9XlitVt9YSkoKHA4H2tvb/eYOGDAA1dXVKC0tRXt7O3bs2IHIyEjcd999gamciHRn0jLZ6XRi4MCBCAsL843FxMTA4/GgqakJUVFRvvGJEyfi4MGDmDVrFvr06QOj0YgNGzbg7rvv1lSgwdDx6M0662cfPUeo9KJ3/ZoCwu12+4UDAN9yW1ub33hjYyOcTideffVVJCUl4S9/+QtycnKwc+dOREdH3/J7RkX101JijxYdHRq9hEofQGj1ogdNAREeHt4lCDqXzWaz3/jatWsxYsQIPPnkkwCAgoICTJgwAdu3b8fChQtv+T0bGppxw9lLr2MwdPwh1tc3Q+ROV9N9odIHEDq9GI36fohqCojY2Fg0NjbC6/XCZOpY1el0wmw2o3///n5zT5w4gdmzZ/uWjUYjRo4cifPnz2sqUAS9egNeL1R6CZU+gN7fi961a7pIGR8fD5PJhLKyMt9YaWkpEhISYDT6v9TgwYNx6tQpv7HTp0/j3nvv7X61RBRUmgIiIiICGRkZyM/PR3l5OQ4cOIDCwkLMmTMHQMfRRGtrKwBg+vTp2LZtG9577z2cOXMGa9euxfnz55GZmRn4LohIF5pOMQAgJycH+fn5mDt3LiIjI7FkyRKMGzcOAGC327Fq1SpMmTIFEydOREtLCzZs2ICLFy8iPj4eRUVFmi5QEtGdZRDp2Wdg9fWhcZEyJqYf6up69wWxUOkDCJ1ejEZ9v4nhzVpEpMSAICIlBgQRKTEgiEiJAUFESgwIIlJiQBCREgOCiJQYEESkxIAgIiUGBBEpMSCISIkBQURKDAgiUmJAEJESA4KIlBgQRKTEgCAiJQYEESkxIIhIiQFBREoMCCJSYkAQkRIDgoiUGBBEpMSAICIlBgQRKTEgiEiJAUFESgwIIlJiQBCREgOCiJQYEESkxIAgIiXNAeHxeJCbmwubzQa73Y7CwkLl3C+++AIzZ85EYmIi0tPTceTIkdsqloiCS3NArFmzBhUVFSgqKkJeXh7Wr1+PkpKSLvOam5vxzDPPYPjw4fjb3/6GtLQ0PPfcc6ivrw9I4USkP00B4XK5UFxcjOXLl8NisSAtLQ1ZWVnYunVrl7k7d+7EXXfdhfz8fAwZMgRLly7FkCFDUFFREbDiiUhfJi2TKysr4fV6YbVafWMpKSl4++230d7eDqPxf3lz7NgxjB07Fn369PGNbd++PQAlE1GwaDqCcDqdGDhwIMLCwnxjMTEx8Hg8aGpq8pt77tw5REVF4ZVXXkFqaiqmT5+O0tLSgBRNRMGhKSDcbrdfOADwLbe1tfmNu1wubNy4EYMGDcKmTZvw4IMPYv78+bhw4YKmAg2G0HiESi+h0kco9aInTacY4eHhXYKgc9lsNvuN9+nTB/Hx8Vi6dCkA4IEHHsDhw4exa9cuPPvss7f8nlFR/bSU2KNFR4dGL6HSBxBavehBU0DExsaisbERXq8XJlPHqk6nE2azGf379/ebO2jQIAwdOtRv7P7779d8BNHQ0Iz2dk2r9DgGQ8cfYn19M0TudDXdFyp9AKHTi9Go74eopoCIj4+HyWRCWVkZbDYbAKC0tBQJCQl+FygBYNSoUfjkk0/8xmpqajBp0iRNBYqgV2/A64VKL6HSB9D7e9G7dk3XICIiIpCRkYH8/HyUl5fjwIEDKCwsxJw5cwB0HE20trYCAGbMmIEvvvgCb731Fs6cOYPf/e53OHfuHCZPnhz4LohIF5p/KJWTkwOLxYK5c+dixYoVWLJkCcaNGwcAsNvt2LNnDwDg29/+NjZv3oxDhw5h0qRJOHToEDZu3IjY2NjAdkBEujGI9OwDrPr60LgGERPTD3V1vft8N1T6AEKnF6NR3wutvFmLiJQYEESkxIAgIiUGBBEpMSCISIkBQURKDAgiUmJAEJESA4KIlBgQRKTEgCAiJQYEESkxIIhIiQFBREoMCCJSYkAQkRIDgoiUGBBEpMSAICIlBgQRKTEgiEiJAUFESgwIIlJiQBCREgOCiJQYEESkxIAgIiUGBBEpMSCISIkBQURKDAgiUmJAEJESA4KIlBgQRKTEgCAiJc0B4fF4kJubC5vNBrvdjsLCwm9c5z//+Q+sViuOHj3arSKJ6M4waV1hzZo1qKioQFFREc6fP4+XXnoJ99xzD8aPH69cJz8/Hy6X67YKJaLg0xQQLpcLxcXF2LRpEywWCywWC6qqqrB161ZlQPz1r39FS0tLQIolouDSdIpRWVkJr9cLq9XqG0tJSYHD4UB7e3uX+Y2NjXj99dfx2muv3X6lRBR0mo4gnE4nBg4ciLCwMN9YTEwMPB4PmpqaEBUV5Td/9erVyMzMxPe+971uF2gwdDx6s8762UfPESq96F2/poBwu91+4QDAt9zW1uY3/s9//hOlpaXYvXv3bRUYFdXvttbvSaKjQ6OXUOkDCK1e9KApIMLDw7sEQeey2Wz2jbW2tuLVV19FXl6e33h3NDQ04yZnL72KwdDxh1hf3wyRO11N94VKH0Do9GI06vshqikgYmNj0djYCK/XC5OpY1Wn0wmz2Yz+/fv75pWXl+PcuXNYunSp3/oLFixARkaGpmsSIujVG/B6odJLqPQB9P5e9K5dU0DEx8fDZDKhrKwMNpsNAFBaWoqEhAQYjf+73pmYmIh9+/b5rTtu3Dj8+te/RmpqagDKJqJg0BQQERERyMjIQH5+Pn7zm9+gtrYWhYWFWLVqFYCOo4l+/frBbDZjyJAhXdaPjY1FdHR0YConIt1p/iVlTk4OLBYL5s6dixUrVmDJkiUYN24cAMBut2PPnj0BL5KI7gyDSM8+A6uvD42LlDEx/VBX17sviIVKH0Do9GI06vtNDG/WIiIlBgQRKTEgiEiJAUFESgwIIlJiQBCREgOCiJQYEESkxIAgIiUGBBEpMSCISIkBQURKDAgiUmJAEJESA4KIlBgQRKTEgCAiJQYEESkxIIhIiQFBREoMCCJSYkAQkRIDgoiUGBBEpMSAICIlBgQRKTEgiEiJAUFESgwIIlJiQBCREgOCiJQYEESkxIAgIiUGBBEpaQ4Ij8eD3Nxc2Gw22O12FBYWKud+9NFHmDx5MqxWK9LT0/Hhhx/eVrFEFFyaA2LNmjWoqKhAUVER8vLysH79epSUlHSZV1lZieeeew5Tp07Fe++9hxkzZuAXv/gFKisrA1I4EenPpGWyy+VCcXExNm3aBIvFAovFgqqqKmzduhXjx4/3m7t792489NBDmDNnDgBgyJAhOHjwID744AOMHDkycB0QkW40BURlZSW8Xi+sVqtvLCUlBW+//Tba29thNP7vgCQzMxPXrl3r8hrNzc23US4RBZOmgHA6nRg4cCDCwsJ8YzExMfB4PGhqakJUVJRvfNiwYX7rVlVV4eOPP8aMGTM0FWgwdDx6s8762UfPESq96F2/poBwu91+4QDAt9zW1qZcr6GhAUuWLEFycjLGjh2rqcCoqH6a5vdk0dGh0Uuo9AGEVi960BQQ4eHhXYKgc9lsNt90nbq6Ojz99NMQEaxbt87vNORWNDQ0o71d0yo9jsHQ8YdYX98MkTtdTfeFSh9A6PRiNOr7IaopIGJjY9HY2Aiv1wuTqWNVp9MJs9mM/v37d5l/6dIl30XKd955x+8U5FaJoFdvwOuFSi+h0gfQ+3vRu3ZNH+fx8fEwmUwoKyvzjZWWliIhIaHLkYHL5UJWVhaMRiO2bNmC2NjYgBRMRMGjKSAiIiKQkZGB/Px8lJeX48CBAygsLPQdJTidTrS2tgIANmzYgLNnz+K3v/2t7zmn08lvMYh6EYOItoMUt9uN/Px87Nu3D5GRkZg/fz7mzZsHAIiLi8OqVaswZcoUjB8/HqdPn+6yfmZmJlavXn3L71dfHxrXIGJi+qGurnef74ZKH0Do9GI06nuhVXNABBsDoucIlT6A0OlF74DgzVpEpMSAICIlBgQRKTEgiEiJAUFESgwIIlJiQBCREgOCiJQYEESkxIAgIiUGBBEpMSCISIkBQURKDAgiUmJAEJESA4KIlBgQRKTEgCAiJQYEESkxIIhIiQFBREoMCCJSYkAQkRIDgoiUGBBEpMSAICIlBgQRKTEgiEiJAUFESgwIIlJiQBCREgOCiJQYEESkxIAgIiXNAeHxeJCbmwubzQa73Y7CwkLl3M8//xxPPPEEkpKSMHXqVFRUVNxWsUQUXJoDYs2aNaioqEBRURHy8vKwfv16lJSUdJnncrmwcOFC2Gw27NixA1arFdnZ2XC5XAEpnIj0pykgXC4XiouLsXz5clgsFqSlpSErKwtbt27tMnfPnj0IDw/HsmXLMGzYMCxfvhx9+/a9aZgQUc+kKSAqKyvh9XphtVp9YykpKXA4HGhvb/eb63A4kJKSAoPBAAAwGAxITk5GWVnZ7VdNREFh0jLZ6XRi4MCBCAsL843FxMTA4/GgqakJUVFRfnOHDx/ut350dDSqqqo0FWgwAMZefin1vxkJoxEQubO13I5Q6QMInV46+9CLpoBwu91+4QDAt9zW1nZLc2+c902iovppmt+ThUovodIHEFq96EHTZ3N4eHiXHbxz2Ww239LcG+cRUc+lKSBiY2PR2NgIr9frG3M6nTCbzejfv3+XuXV1dX5jdXV1GDx48G2US0TBpCkg4uPjYTKZ/C40lpaWIiEhAcYbLhQkJSXh008/hfz3BE9EcPz4cSQlJd1+1UQUFJoCIiIiAhkZGcjPz0d5eTkOHDiAwsJCzJkzB0DH0URraysAYPz48bhy5QpWrlyJ6upqrFy5Em63GxMmTAh8F0SkC4OItmu4brcb+fn52LdvHyIjIzF//nzMmzcPABAXF4dVq1ZhypQpAIDy8nLk5eXh1KlTiIuLw4oVK/DAAw8EvAki0ofmgCCi/z96+S8MiEhPDAgiUmJAEJFSUAMikLeK7969G48++iiSkpKwePFiNDQ06F2+Hy29fPTRR5g8eTKsVivS09Px4Ycf+j1vs9kQFxfn92hpadG7BQDa+li0aFGXOg8dOuR7/s9//jMeeeQRWK1W5Obmwu12B6MFn1vtZfbs2V36iIuLQ05ODgDg8uXLXZ4bPXp0MFsB0PHDwkmTJuHo0aPKObrvJxJEr732mqSnp0tFRYXs27dPrFarfPDBB13mtbS0SGpqqqxevVqqq6uloKBAfvjDH0pLS4uIiDgcDklMTJSdO3fKyZMn5amnnpKFCxcGs5Vb7uXkyZNisVikqKhIvvzyS9myZYtYLBY5efKkiIhcvHhRRowYIWfPnpXa2lrfo729vUf1ISKSlpYmu3bt8qvT4/GIiEhJSYmkpKTIwYMHxeFwyMSJE2XFihVB6aHTrfbS2Njo18P+/fvFYrFIeXm5iIj861//kh/84Ad+c+rq6oLaS2trqyxevFhGjBghR44cuemcYOwnQQuIlpYWSUhI8Gv297//vTz11FNd5hYXF8tPfvIT307S3t4uaWlpsn37dhER+dWvfiUvvfSSb/758+clLi5Ozp49q3MXHbT08vrrr8v8+fP9xp555hl54403RETk8OHDkpqaqm/BClr68Hg8Eh8fLzU1NTd9rVmzZsm6det8y5988okkJiaKy+UKfOE3oaWX63m9Xpk4caK8+eabvrFt27bJz372M71K/UZVVVXy+OOPS3p6+tcGRDD2k6CdYgTyVnGHwwGbzeab/61vfQv33HMPHA6H/o1AWy+ZmZl48cUXu7xGc3MzAKC6uhrf/e539S1YQUsfNTU1MBgM+M53vtPldb766it89tlnfttk1KhRuHbtGiorK/Vr4Dpaernejh07cPnyZSxYsMA3Vl1djfvvv1/Pcr/WsWPHMHr0aLz77rtfOy8Y+0nQAuKbbhW/ce6N92xER0fj4sWLAIDa2tqvfV5vWnoZNmwYRo4c6VuuqqrCxx9/jIcffhgAcOrUKbjdbsyePRt2ux0LFizA6dOne1wfNTU1iIyMxLJly2C32zFt2jT8/e9/BwBcuXIFHo/Hb5uYTCYMGDCgR26TTiKCzZs3Y86cOejbt69v/NSpU7h48SKmTZuGRx55BM8//zxqa2v1bsFn1qxZyM3NRURExNfOC8Z+ErSACOSt4q2trQG5lby7tPRyvYaGBixZsgTJyckYO3YsgI4d7/Lly1i0aBH+8Ic/wGw2Y968ebh69ap+DfyXlj5qamrQ2toKu92OzZs3Y8yYMVi0aBE+++wz38/re9s2OXr0KC5evIjp06f7jdfU1ODq1avIycnBm2++idraWjz77LP46quv9Cm+m4Kxn2j6fxC3I5C3ique/6bEDRQtvXSqq6vD008/DRHBunXrfDe3/fGPf8S1a9d8n2Br167FmDFjcOjQIaSnp+vYhbY+fv7zn2P27Nm4++67AQAjR47EiRMnsG3bNjz//PN+617/Wj15m+zduxc/+tGPMGDAAL/x999/HwaDwbfeunXrYLfb4XA4kJycHPjiuykY+0nQjiACeau46vlBgwbpVL0/Lb0AwKVLl/Dkk0+ira0N77zzjt9/3goLC/M7vA0PD8e9996LS5cu6dsEtPVhNBp94dBp6NChuHTpEgYMGIDw8HC/beL1etHU1NRjtwkA/OMf//AdyV0vIiLCL1Sio6MxYMCAoGwTLYKxnwQtIAJ5q3hSUhJKS0t98y9cuIALFy4E7VZyLb24XC5kZWXBaDRiy5YtiI2N9T0nInj00UexY8cOv/lnzpzB0KFDe1QfL7/8su93Ap0qKysxdOhQGI1GJCQk+G2TsrIymEwmv+svetLSC9Bxunfu3DmkpKT4jV+9ehUPPvggjhw54hu7dOkSGhsbg7JNtAjKftKdr2G665VXXpHHHntMHA6H7N+/X5KTk2Xv3r0iIlJbWytut1tERJqbm+Whhx6SgoICqaqqkoKCAklNTfV9v3v8+HGxWCyybds23/e72dnZwWzllnt54403JDExURwOh9/36leuXBERkYKCAvnxj38sR44ckX//+9+yePFimTRpkni93h7Vx969e8ViscjOnTvlyy+/lLfeeksSExPl3LlzIiKye/duSU5Olv3794vD4ZDHHntMCgoKgtKD1l5ERI4cOSIJCQk3/b1Jdna2PP744+JwOKSiokJmzpwpWVlZQevjejd+zRns/SSoAeFyuWTZsmUyatQosdvt8qc//cn33IgRI3zf34p0/MgjIyNDEhISZNq0aXLixAm/19q+fbuMGTNGRo0aJYsXL5aGhoZgtSEit97LT3/6UxkxYkSXR+f3062trbJq1SpJTU2VpKQkyc7OlvPnz/e4PkQ6fh8wbtw4+f73vy+ZmZly7Ngxv9fasGGDPPzww5KSkiI5OTnS2toarDZERFsv77//vvL3J01NTfLyyy/L6NGjxWq1yosvvihNTU16l39TNwZEsPcT3u5NREq8WYuIlBgQRKTEgCAiJQYEESkxIIhIiQFBREoMCCJSYkAQkRIDgoiUGBBEpMSAICIlBgQRKf0fi/c2b6Y3iRIAAAAASUVORK5CYII="
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T14:50:30.760630Z",
     "start_time": "2025-08-10T19:52:45.181241Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Quick training\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in range(10):  # Just a few epochs for demo\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for data_tuple in dataloader:\n",
    "        # Unpack data from TensorDataset\n",
    "        data = data_tuple[0]  # Unpack from TensorDataset\n",
    "\n",
    "        # Debug: Print shapes to identify the issue\n",
    "        print(f\"Data tuple type: {type(data_tuple)}\")\n",
    "        print(f\"Data tuple length: {len(data_tuple)}\")\n",
    "        print(f\"Raw data shape: {data.shape}\")\n",
    "\n",
    "        data = data.to(device)\n",
    "        print(f\"Data shape after .to(device): {data.shape}\")\n",
    "\n",
    "        # This should be [8, 1, 32]\n",
    "        if data.shape[1] != 1:\n",
    "            print(f\"ERROR: Expected 1 channel, got {data.shape[1]} channels\")\n",
    "            break\n",
    "\n",
    "        loss = ddpm.train_loss(data)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch}, Loss: {total_loss/len(dataloader):.4f}\")\n",
    "\n",
    "# Cell 5: Generate samples\n",
    "visualize_final_samples(ddpm, device, num_samples=4, seq_len=32)"
   ],
   "id": "486f3fda1baeeb18",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data tuple type: <class 'list'>\n",
      "Data tuple length: 1\n",
      "Raw data shape: torch.Size([8, 1, 32])\n",
      "Data shape after .to(device): torch.Size([8, 1, 32])\n",
      "DDPM train_loss input shape: torch.Size([8, 1, 32])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [32, 1, 3], expected input[8, 8, 32] to have 1 channels, but got 8 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mRuntimeError\u001B[39m                              Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[6]\u001B[39m\u001B[32m, line 25\u001B[39m\n\u001B[32m     22\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mERROR: Expected 1 channel, got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdata.shape[\u001B[32m1\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m channels\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     23\u001B[39m     \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m25\u001B[39m loss = \u001B[43mddpm\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtrain_loss\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     27\u001B[39m optimizer.zero_grad()\n\u001B[32m     28\u001B[39m loss.backward()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/diffusion_gnn/diffusion_gnn/core/ddpm.py:53\u001B[39m, in \u001B[36mDDPM.train_loss\u001B[39m\u001B[34m(self, x_0)\u001B[39m\n\u001B[32m     50\u001B[39m x_t = \u001B[38;5;28mself\u001B[39m.scheduler.q_sample(x_0, t, noise=noise)\n\u001B[32m     52\u001B[39m \u001B[38;5;66;03m# Step 4: Predict noise using the model\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m53\u001B[39m predicted_noise = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_t\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     55\u001B[39m \u001B[38;5;66;03m# Step 5: MSE loss between true and predicted noise\u001B[39;00m\n\u001B[32m     56\u001B[39m loss = F.mse_loss(noise, predicted_noise)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/diff_gnn/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1771\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1772\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1773\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/diff_gnn/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1779\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1780\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1781\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1782\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1783\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1784\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1786\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1787\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/diffusion_gnn/diffusion_gnn/models/unet.py:115\u001B[39m, in \u001B[36mSimpleUNet.forward\u001B[39m\u001B[34m(self, x, timestep)\u001B[39m\n\u001B[32m    112\u001B[39m t = \u001B[38;5;28mself\u001B[39m.time_mlp(timestep)\n\u001B[32m    114\u001B[39m \u001B[38;5;66;03m# Downsampling with skip connections\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m115\u001B[39m h1 = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mdown1\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    116\u001B[39m h2 = \u001B[38;5;28mself\u001B[39m.down2(h1)\n\u001B[32m    118\u001B[39m \u001B[38;5;66;03m# Bottleneck with time conditioning\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/diff_gnn/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1771\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1772\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1773\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/diff_gnn/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1779\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1780\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1781\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1782\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1783\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1784\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1786\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1787\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/diff_gnn/lib/python3.11/site-packages/torch/nn/modules/container.py:244\u001B[39m, in \u001B[36mSequential.forward\u001B[39m\u001B[34m(self, input)\u001B[39m\n\u001B[32m    242\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[32m    243\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[32m--> \u001B[39m\u001B[32m244\u001B[39m         \u001B[38;5;28minput\u001B[39m = \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m    245\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/diff_gnn/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1771\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1772\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1773\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/diff_gnn/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1779\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1780\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1781\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1782\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1783\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1784\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1786\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1787\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/diff_gnn/lib/python3.11/site-packages/torch/nn/modules/conv.py:371\u001B[39m, in \u001B[36mConv1d.forward\u001B[39m\u001B[34m(self, input)\u001B[39m\n\u001B[32m    370\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) -> Tensor:\n\u001B[32m--> \u001B[39m\u001B[32m371\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_conv_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/diff_gnn/lib/python3.11/site-packages/torch/nn/modules/conv.py:366\u001B[39m, in \u001B[36mConv1d._conv_forward\u001B[39m\u001B[34m(self, input, weight, bias)\u001B[39m\n\u001B[32m    354\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.padding_mode != \u001B[33m\"\u001B[39m\u001B[33mzeros\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m    355\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m F.conv1d(\n\u001B[32m    356\u001B[39m         F.pad(\n\u001B[32m    357\u001B[39m             \u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m._reversed_padding_repeated_twice, mode=\u001B[38;5;28mself\u001B[39m.padding_mode\n\u001B[32m   (...)\u001B[39m\u001B[32m    364\u001B[39m         \u001B[38;5;28mself\u001B[39m.groups,\n\u001B[32m    365\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m366\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[43m.\u001B[49m\u001B[43mconv1d\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    367\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mstride\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mdilation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mgroups\u001B[49m\n\u001B[32m    368\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mRuntimeError\u001B[39m: Given groups=1, weight of size [32, 1, 3], expected input[8, 8, 32] to have 1 channels, but got 8 channels instead"
     ]
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
